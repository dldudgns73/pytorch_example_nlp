{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bi_rnn.ipynb의 사본","provenance":[{"file_id":"19V_3z5Y66AfFlAHyGscXTSULFWOV2cZN","timestamp":1570643551282},{"file_id":"11PnwRk0fR8NQjAGSe3QMnSmVt1-NkNEt","timestamp":1570643318085},{"file_id":"10ICeEcwi7VjaLQPWKpDiJvrMR9wHv1-h","timestamp":1570635227926},{"file_id":"1tYPLOFgSfFAuXaLx3PxIF-bZx-VHndnY","timestamp":1570634774485}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"AG3zZCKNEMDH","colab_type":"code","colab":{}},"source":["import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ADfBaeGkEQqg","colab_type":"text"},"source":["# Device configuration"]},{"cell_type":"code","metadata":{"id":"-5Y0c6njER4_","colab_type":"code","colab":{}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5MzAqUMIEUA4","colab_type":"text"},"source":["# Hyper-parameters"]},{"cell_type":"code","metadata":{"id":"uWeaXha-EWfz","colab_type":"code","colab":{}},"source":["sequence_length = 28\n","input_size = 28\n","hidden_size = 128\n","num_layers = 2\n","num_classes = 10\n","batch_size = 100\n","num_epochs = 2\n","learning_rate = 0.003"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N07EHTvFEW8C","colab_type":"text"},"source":["# MNIST dataset"]},{"cell_type":"code","metadata":{"id":"8FMmTU6eEYBP","colab_type":"code","colab":{}},"source":["train_dataset = torchvision.datasets.MNIST(root='../../data/',\n","                                           train=True, \n","                                           transform=transforms.ToTensor(),\n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='../../data/',\n","                                          train=False, \n","                                          transform=transforms.ToTensor())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UZrpr5AZEZ7I","colab_type":"text"},"source":["# Data loader"]},{"cell_type":"code","metadata":{"id":"jFAZQWo8EbSU","colab_type":"code","colab":{}},"source":["train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYDHVNIuEjRa","colab_type":"text"},"source":["# Bidirectional recurrent neural network (many-to-one)"]},{"cell_type":"code","metadata":{"id":"I65QY0juEnet","colab_type":"code","colab":{}},"source":["class BiRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(BiRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n","    \n","    def forward(self, x):\n","        # Set initial states\n","        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n","        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n","        \n","        # Forward propagate LSTM\n","        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n","        \n","        # Decode the hidden state of the last time step\n","        out = self.fc(out[:, -1, :])\n","        return out\n","\n","model = BiRNN(input_size, hidden_size, num_layers, num_classes).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ppMcr5PIEqHd","colab_type":"text"},"source":["# Loss and optimizer"]},{"cell_type":"code","metadata":{"id":"mbD_YM19Erf0","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZUSwu4xqEsVl","colab_type":"text"},"source":["# Train the model"]},{"cell_type":"code","metadata":{"id":"ari5Oo0jEtHe","colab_type":"code","colab":{}},"source":["total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.reshape(-1, sequence_length, input_size).to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vDfKJmAmEu8D","colab_type":"text"},"source":["# Test the model"]},{"cell_type":"code","metadata":{"id":"AB0se0jjEv8J","colab_type":"code","colab":{}},"source":["with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.reshape(-1, sequence_length, input_size).to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ThzqAF1E2FA","colab_type":"text"},"source":["\n","# Save the model checkpoint"]},{"cell_type":"code","metadata":{"id":"Dr5dzyduIIvy","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), 'model.ckpt')"],"execution_count":0,"outputs":[]}]}